library(tidyverse)
library(tools)
# change dir name!
curent_project_name <- readline(prompt = "Print your project name: ")
egregious_violators
curent_file_name_no_ext <- readline(prompt = "Print your file name: ")
egregious_violators_start

# In the input .R script:
# add "#' " in front of comments to be shown as text
# and #' as the last line of the visible comments
# add #+, file = prep_addresses_path, instead of a source, to be converted in a chunk

# In the output .qmd:
# *) merge "# save setup chunk options to use later" with the next chunk
# *) add |>
#   knitr::kable(caption = "My Caption")
# for pretty tables

# setup ----
# test_function
check_str <- function(my_string, my_pattern) {
  my_string |>
    stringr::str_extract(my_pattern) |>
    as.data.frame() |>
    setNames(nm = "found") |>
    filter(!is.na(found))
}

# source("~/R_code_github/useful_functions_module.r")
library(auxfunctions)
my_paths <- set_work_dir()

dir_to_comb <-
  file.path(my_paths$git_r,
            curent_project_name)

dir.exists(dir_to_comb)

file_name <- curent_file_name_no_ext
  # curent_project_name
file_ext <- c("R", "Rmd", "qmd")

# Create a list of file paths for each file extension.
file_paths <-
  purrr::map(file_ext,
      ~ file.path(dir_to_comb,
                  paste0(file_name, ".", .x)))

# Set the names of the list elements to 'file_ext'.
names(file_paths) <- file_ext

# prepare all pieces ----
## read the main file content ----
flat_file_r_text <-
  readLines(file_paths$R)

head(flat_file_r_text)

## read all sourced files ----
# grep("source", flat_file_r_text, value = T)

find_source_paths <- function(my_text = flat_file_r_text) {
  source_path_all_list <-
    my_text |>
    str_extract_all("^\\s*[^#]*source\\((.+)\\)") |>
    unique()
  
  source_path_list <-
    purrr::discard(source_path_all_list, ~ length(.x) == 0)
  
  return(source_path_list)
}

source_paths_matches <- find_source_paths()

find_source_path_vars <-
  function(my_text = flat_file_r_text,
           source_paths_matches = source_paths_matches) {
    source_path_vars <-
      source_paths_matches |>
      map(\(one_var) {
        stringr::str_replace(one_var, "\\w+\\((.+)_path\\)", "\\1")
      })
    
    return(source_path_vars)
  }

source_path_var_names <- 
  find_source_path_vars(my_text = flat_file_r_text, 
           source_paths_matches = source_paths_matches)

# assuming files are named by convention:
# FILE_NAME_PART_path
# {curent_project_name}_{FILE_NAME_PART} in the current project directory dir_to_comb

make_source_path <- function(dir_to_comb, source_path_var_names) {
  source_path_var_names |>
    map(\(source_path_var_name) {
      file.path(dir_to_comb, 
                paste0(curent_project_name, "_", source_path_var_name, ".R"))
    })
}

source_paths <- make_source_path(dir_to_comb, source_path_var_names)

read_source_files <- function(source_paths) {
  file_content <-
    source_paths |>
    map(\(one_path) {
      if (file.exists(one_path)) {
        one_text <-
          readLines(one_path)
      }
    })
  return(file_content)
}

source_files_content <- read_source_files(source_paths) |>
  set_names(source_paths_matches)

# View(source_files_content)

## combine all files ----

## find sourced files ----
# check
# grep("file =", flat_file_r_text, value = T)

# replace sourcing files with file content
comment_out_sources <-
  function(my_text = flat_file_r_text) {
    # browser()

    # View(source_files_content)
    
    to_find <- str_c("\\b", str_escape(unlist(source_paths_matches)), "\\b",
                     collapse = "|")
    # str(to_find)

    # one_match <- "source(get_data_path)"
    to_replace1 <-
      function(one_match) {
        browser()
        paste("<<<@1@>>>", one_match)
        # str_escape(source_files_content[[one_match]])
      }

    rrr <-
      str_replace_all(flat_file_r_text, to_find, to_replace1)
    
    View(rrr)
    
    grep("<<@", rrr, value = T)
    # str_escape(source_paths_matches[[1]])
    my_res_text <-
      str_replace_all(flat_file_r_text, 
                      c("source\\(get_data_path\\)" = "<<<@1@>>>",
                        "source\\(prep_addresses_path\\)" = "<<<@2@>>>")
                      # c(source_paths_matches[[1]] = "<<<@1@>>>",
                      #   source_paths_matches[[2]] = "<<<@2@>>>")
                      #     # source_files_content[[2]])
                      )

    grep("<<@", my_res_text, value = T)
    
    my_res_text <-
        # str_replace_all(c("one" = "1", "two" = "2", "three" = "3"))

      stringr::str_replace(my_text,
        source_paths_matches,  
        "<<<@@>>>"
        # str_glue("#' \\1", 
        #          {""})
        
# "#+, file = \\1"
      )
    
    return(my_res_text)
  }

flat_file_r_text <- comment_out_sources(flat_file_r_text)


## Add headers to the flat file to be converted by knitr ----
# In this code, 'flat_file_r_text' is generated by modifying the text content read from the file specified by 'r_file_name'. The 'gsub' function is used to replace specific patterns in the text:
#
# It searches for lines that start with one or more '#' symbols followed by a space, captures the content after that, and then captures a line with "----" at the end.
# It replaces this pattern with a modified format, adding "#'" at the beginning of the first line for headers,
# and copying the pattern on the second line to keep comments in place.
# This transformation is used to adapt R script file to an R Markdown format by converting header lines to Roxygen-style comments.
#

# In this code, 'flat_file_r_text' is modified using the 'gsub' function to replace specific patterns in the text. The pattern being searched for is defined using a regular expression.
# It automatically makes chunk titles

unify_comments <-
  function(flat_file_r_text) {
    flat_file_r_text <-
      gsub(" ====",
           " ----",
           flat_file_r_text)
    return(flat_file_r_text)
  }

make_chunk_titles_from_comments <-
  function(flat_file_r_text) {

    pattern_to_add_md_headers <- "#' \\1\\2"
    pattern_to_add_md_chunk_labels <- "#+ \\2"
    pattern_to_repeat_the_original <- "\\1\\2\\3"

    flat_file_r_text <-
      unify_comments(flat_file_r_text)

    flat_file_r_text <-
      gsub(
        "^(#+ )(.+)(----)",
        paste(
          pattern_to_add_md_headers,
          pattern_to_add_md_chunk_labels,
          pattern_to_repeat_the_original,
          sep = "\\\n"
        ),
        flat_file_r_text
      )

    return(flat_file_r_text)
  }

flat_file_r_text <-
  make_chunk_titles_from_comments(flat_file_r_text)

# It searches for lines starting with "#+" followed by a space and captures the content after that.
# It captures a single quote or a slash.
# It captures more content.
# It captures a newline character.
# Remove all "odd" characters from chunk titles for knitr to work with.
# repeat twice
# 
clean_chunk_titles <-
  function(flat_file_r_text) {
    
    while (any(stringr::str_detect(flat_file_r_text, 
                          "#\\+[^#]*[^A-z0-9#+ ]+[^#]+"))) {
      flat_file_r_text <-
        flat_file_r_text |>
        stringr::str_replace_all("(#\\+[^#]*)[^A-z0-9#+ ]+([^#]+)", "\\1\\2")
      
    }
    
    return(flat_file_r_text)
  }

flat_file_r_text <-
  clean_chunk_titles(flat_file_r_text)

# check
# grep("how many are duals", flat_file_r_text, value = T)

## Change all sections to a level lower ----
# works with the next step, convert %%%%% to the level 1
lower_section_level <-
  function(flat_file_r_text) {
    flat_file_r_text <-
      gsub("(#+) (.+)(----)",
           "\\1# \\2\\3",
           flat_file_r_text)
    return(flat_file_r_text)
  }

flat_file_r_text <-
  lower_section_level(flat_file_r_text)

## add 2 top sections ----
# E.g. "Prepare data" and "Plots", marked in the R script with #' %%%%%
# like #' %%%%% Prepare data
# not used in the auxiliary files

add_topmost_sections <- function(flat_file_r_text) {
  flat_file_r_text <-
    gsub("(%%%%%+) ", # was defined in the original .R
         "# ",
         flat_file_r_text)

  return(flat_file_r_text)
}

flat_file_r_text <-
  add_topmost_sections(flat_file_r_text)

## add layouts
add_layouts <- function(flat_file_r_text) {
  flat_file_r_text <-
    gsub(
      "(^#\\|)", # was defined in the original .R
      "#|",
      flat_file_r_text
    )
  return(flat_file_r_text)
}

flat_file_r_text <- add_layouts(flat_file_r_text)

# add "pretty" table output (add kable to glimpse)
add_pretty_table <-
  function(flat_file_r_text) {
    flat_file_r_text <-
      gsub(
      "(^ *[^#] +)(glimpse)(\\(\\S*\\))",
      # was in the original .R
      '\\1\\2\\3 |>
\\1knitr::kable(caption = "")',
flat_file_r_text
    )
    return(flat_file_r_text)
  }

flat_file_r_text <-
  add_pretty_table(flat_file_r_text)

# add my functions' descriptions ----

## if with auxfunctions:: prefix ----

in_text <- flat_file_r_text
get_my_func_names_w_prefix <- function(in_text) {
  
  str_extract(in_text,
              "auxfunctions::\\w+\\(") |> 
    unique() |> 
    na.omit()

  # my_used_function_names <-
  #   grep("auxfunctions::\\w+\\(", in_text, value = TRUE) |> 
  #   unique()
  # 
  return(my_used_function_names)
}

find_all_input_files <-
  function(in_text, search_str = "file = ") {
    # grep("file = ", in_text, value = T)
    to_search <- str_glue("{search_str}(\\w+)")
    
    in_text |>
      str_extract(to_search) |>
      unique() |>
      na.omit() |>
      str_replace_all(to_search, "\\1")
    
  }

my_used_function_names <- find_all_input_files(flat_file_r_text)

## through "naked" functions ----
  
get_my_func_names_naked <- function(in_text) {
  ### get all auxfunctions names ----
  auxfunctions_list <- getNamespaceExports("auxfunctions")
  
  ### list of used functions ----
  used_naked_functions <-
    check_str(in_text, "\\w+\\(")$found |>
    strsplit(",") |>
    stringr::str_sub(end = -2) |>
    unique()
  
  ### find which used functions are from the auxfunctions package ----
  # TODO: use on qmd file with included aux files?
  my_used_function_names <-
    dplyr::intersect(auxfunctions_list, used_naked_functions)
  
  return(my_used_function_names)
}

# my_used_function_names <- get_my_func_names_naked()

## a function to get function help as a text ----
get_help_text <- function(function_name) {
  # browser()
  used_tags <- c("description", "details")
  help_text <-
    help(function_name, "auxfunctions") |>
    utils:::.getHelpFile()
  
  used_tags_help_list <-
    map(used_tags, \(one_tag) {
      help_text |>
        purrr::keep( ~ attr(.x, "Rd_tag") == paste0("\\", one_tag)) |>
        purrr::map(as.character) %>%
        purrr::flatten_chr() %>%
        paste0(., collapse = "")
    }) |>
    setNames(used_tags)
  
  used_tags_help <- 
    paste(used_tags_help_list[[1]],
          "\n",
          used_tags_help_list[[2]])
  
  used_tags_help_commented <- 
    used_tags_help |> 
    str_replace_all("\n", "\n# ")
  
  return(used_tags_help_commented)
}

## a function to get function obj as a text ----
function_obj_as_text <- function(function_name) {
  # remove environment descriptions
  fun_body <- paste(capture.output(function_name), collapse = "\n") |>
    str_replace_all("\\n<.+", "")
  
  return(fun_body)
}

## get all my_used_function_texts ----
my_used_function_texts <-
  my_used_function_names |>
  map(\(one_f_name) {
    function_list <- getAnywhere(one_f_name)
    
    function_as_text <-
      function_list$objs[[1]] |> function_obj_as_text()
    
    with_first_line <- 
      paste(one_f_name, " <- ",
            function_as_text)
    
    return(with_first_line)
  }) |> 
  set_names(my_used_function_names)

## get all my used function helps ----
my_used_function_helps <-
  my_used_function_names |>
  map(\(one_f_name) {
    get_help_text(one_f_name)
  }) |>
  set_names(my_used_function_names)

## repeat the same for each source files ----

## Paste function code and description before it is used ----

# check
# grep("@", flat_file_r_text, value = T)
# 0

my_split_newline_char <- "@@@"

to_one_line <-
  function(my_text_with_newline, 
           glue_by = my_split_newline_char) {
    my_text_with_newline |>
      paste(collapse = glue_by)
  }

split_one_line_text_back <-
  function(my_text_with_at, split_by = my_split_newline_char) {
    strsplit(my_text_with_at, split_by)[[1]]
  }

replace_one_in_each <- 
  function(flat_file_r_text, idx) {
    # browser()
    to_find <- str_glue("(",
                        my_split_newline_char,
                        ".+{my_used_function_names[[idx]]})")
    to_replace_with <-
      paste(
        "\n# <<<<",
        my_used_function_texts[[idx]],
        "\n# Explanations:",
        my_used_function_helps[[idx]],
        "# >>>>",
        "\\1", #to keep in place what's found
        sep = "\n"
      )
    
    one_line_text <-
      to_one_line(flat_file_r_text, my_split_newline_char)
    
    one_line_text_replaced <-
      str_replace(one_line_text, to_find, to_replace_with)
    
    text_replaced <-
      split_one_line_text_back(one_line_text_replaced)
    
    return(text_replaced)
  }

flat_file_r_text <-
  purrr::reduce(seq_len(length(my_used_function_names)),
                \(acc, nxt) replace_one_in_each(acc, nxt), 
                .init = flat_file_r_text)

see_res_in_outfile <- function(text_to_output) {
  outfile <- tempfile(fileext = ".txt")
  cat(text_to_output, file = outfile)
  file.show(outfile)
}

# see_res_in_outfile(flat_file_r_text)

# convert to Rmd ----
# The 'knitr::spin' function is used to create an R Markdown (Rmd) file, but the 'knit' argument is set to 'FALSE', indicating that the document should not be fully knitted. Instead, this function generates an Rmd file from the R script without executing the code chunks.

tictoc::tic("rmd_text")
rmd_text <-
  knitr::spin(text = flat_file_r_text,
              knit = FALSE,
              format = 'qmd')
tictoc::toc()
# rmd_text: 0.11 sec elapsed

# rmd_text |>
#   stringr::str_extract("````") |>
#   as.data.frame() |>
#   setNames(nm = "found") |> 
#   filter(!is.na(found)) |> dim()
# # 86

# Don't use in the auxiliary file
pre_text <- stringr::str_glue("---
title: {curent_project_name}
---
")

# Don't use in the auxiliary file
# Setup
setup_text <- "
```{r no cache setup, results='hide', message=FALSE, warning=FALSE, cache=FALSE, include=FALSE}

# A general-purpose tool for dynamic report generation in R
library(knitr)

# Adds features to a kable output
library(kableExtra)

# Format R code automatically
library(styler)
```

```{r df format setup}
#| include: false
# kable <- function(data) {
#   knitr::kable(data, booktabs = true, digits = 2) %>%
#     kable_styling('striped', full_width = FALSE)
# }

knit_print.data.frame = function(x, ...) {
  res = paste(c(
    '',
    '',
    knitr::kable(x, digits = 2) |>
      kableExtra::kable_styling('striped', full_width = FALSE)
  ),
  collapse = '\n')
  knitr::asis_output(res)
}

registerS3method(
  'knit_print', 'data.frame', knit_print.data.frame,
  envir = asNamespace('knitr')
)

# knitr::opts_chunk$set(echo = TRUE)

# options(knitr.table.format = 'HTML')


```

# save setup chunk options to use later
```{r setup current project, results='hide', message=FALSE, warning=FALSE}
```
"

# combine pieces into a Quarto file ----

# Don't use in the auxiliary file
cat(
  pre_text,
  file = file_paths$qmd,
  # append = TRUE,
  sep = "\n"
)

# ---
# add in front

# # tabset doesn't work with TOC
# cat(
#   '::: {.panel-tabset}',
#   file = file_paths$qmd,
#   append = TRUE,
#   sep = "\n"
# )

# Don't use in the auxiliary file
cat(
  setup_text,
  file = file_paths$qmd,
  append = TRUE,
  sep = "\n"
)

cat(
  rmd_text,
  file = file_paths$qmd,
  append = TRUE,
  sep = "\n"
)

# # for tabset only
# cat(
#   ':::',
#   file = file_paths$qmd,
#   append = TRUE,
#   sep = "\n"
# )
