---
title: "FHIER logbooks problems"
# subtitle:  "(see read.me)"
date: today
project:
  lib-dir: ..
format:
  html:
    toc: true
    # toc-depth: 2
    css: styles.css
    code-overflow: wrap
    # code-fold: true
    code-summary: "Show the code"
    code-line-numbers: true
---

```{r no cache setup, include=FALSE}
##| echo: false
library(zoo)
library(gridExtra)
library(grid)
# install.packages("viridis")
library(viridis)

# include auxilary functions ----
source("~/R_code_github/useful_functions_module.r")
my_paths <- set_work_dir()
```

```{r setup, cache=TRUE, include=FALSE}
##| echo: false
# get data

source("~/R_code_github/compare_catch/compare_catch_data_preparation.R")

### Transmission year ====
# (1) check the transmission year. Anything sent in 2021 we ignore, since it was a testing year for approving apps.
# ```{r Transmission year}

grep("transm", names(logbooks_content), value = T)

logbooks_content_transmission_date_ct <-
  logbooks_content_transmission_date_ok_waves__sa_gom %>%
  mutate(transmission_date_ct = as.POSIXct(transmission_date,
                                           format = "%Y-%m-%d %H:%M:%S"))

#### "start" names ----
grep("start",
     names(logbooks_content_transmission_date_ct),
     value = T)

logbooks_content_dates_ct <-
  logbooks_content_transmission_date_ct %>%
  mutate(
    trip_start_date_ct = as.POSIXct(trip_start_date, format = "%Y-%m-%d %H:%M:%S"),
    trip_end_date_ct = as.POSIXct(trip_end_date, format = "%Y-%m-%d %H:%M:%S")
  )

transmission_date_ok <-
  logbooks_content_dates_ct %>%
  filter(
    trip_start_date < "2022-01-01" |
      trip_start_date > "2023-04-01" |
      trip_end_date < "2022-01-01" |
      trip_end_date > "2023-04-01"
  ) %>%
  filter(transmission_date_ct > "2022-01-01") %>%
  select(-`1`)

# transmission_date_ok %>%
# select(trip_start_date, trip_end_date, transmission_date) %>% 
#   unique() %>%
#   head()
# glimpse()
# Rows: 20
# write.csv(file = "fhier_logbooks_wrong_dates1.csv", row.names = F)

### Get field names into variables
# There are different formats in different available files.
# Find a column name with "itis" in it

logbooks_content_transmission_date_ok <- transmission_date_ok

# names(logbooks_content_transmission_date_ok)

```

## Glimpse logbooks content
```{r logbooks_content_transmission_date_ok}
glimpse(logbooks_content_transmission_date_ok)
```

  
## Wrong dates
```{r logbooks_content wrong dates}

fhier_dates <-
  logbooks_content_transmission_date_ok %>%
  select(grep("date", names(logbooks_content_transmission_date_ok), value = T))

max(fhier_dates$trip_start_date_time)
# [1] "2023-06-13 08:00:00 EDT"
min(fhier_dates$trip_start_date_time)

max(fhier_dates$trip_end_date_time)
# [1] "2023-06-13 16:00:00 EDT"
min(fhier_dates$trip_end_date_time)
# [1] "1969-08-17 12:30:00 EDT"

fhier_dates %>%
  filter(trip_start_date_time < "2022-01-01" |
           trip_start_date_time > "2023-04-01") %>%
  head(1)
# 1

fhier_dates %>%
  filter(trip_end_date_time < "2022-01-01" |
           trip_end_date_time > "2023-04-01")  %>%
  head()
# 34

```

### to csv
```{r logbooks_content wrong dates to csv}
logbooks_content_transmission_date_ok %>%
  filter(
    trip_start_date_time < "2022-01-01" |
      trip_start_date_time > "2023-04-01" |
      trip_end_date_time < "2022-01-01" |
      trip_end_date_time > "2023-04-01"
  ) %>% head()
# %>%
#   write.csv(file = "fhier_logbooks_wrong_dates.csv", row.names = F)
```

## region is not SA or GOM
```{r region is not SA or GOM glimpse}

# glimpse(logbooks_content_transmission_date_ok)

logbooks_content_transmission_date_ok %>%
  filter(!(end_port_sa_gom %in% c("sa", "gom"))) %>%
  glimpse()
# Rows: 188
```
  
### not_specified_region_states
```{r not_specified_region_states}
not_specified_region <-
  logbooks_content_transmission_date_ok %>%
  filter(!(end_port_sa_gom %in% c("sa", "gom")))

not_specified_region_states <-
  not_specified_region %>%
  select(
    vessel_official_nbr,
    trip_id,
    in_state,
    latitude,
    longitude,
    area_code,
    sub_area_code,
    distance_code,
    distance_code_name,
    local_area_code,
    state,
    state_name,
    start_port,
    start_port_name,
    start_port_county,
    start_port_state,
    end_port,
    end_port_name,
    end_port_county,
    end_port_state
  )

head(not_specified_region_states)

```
  
### Specifics
```{r Specifics}

not_specified_region_states_not_monroe <-
  not_specified_region_states %>%
  filter(end_port_county == "NOT-SPECIFIED" &
           start_port_county != "MONROE")

not_specified_region_states_not_monroe %>%
  select(vessel_official_nbr) %>% unique()
  # 1244719
  # glimpse()
not_specified_region_states_not_monroe %>%
  select(state_name) %>% unique()
  # FLORIDA

not_specified_region_states_not_monroe %>%
  select(end_port) %>% unique()
  # 100999

not_specified_region_states_not_monroe %>%
  select(start_port_name) %>% unique()
# FLORIDA(STATE)

```
  
### region is not SA or GOM to csv
```{r region is not SA or GOM to csv}

logbooks_content_transmission_date_ok_waves_fl_county %>%
  filter(state_name == 'FLORIDA') %>%
  filter(!(end_port_fl_reg %in% c("sa", "gom"))) %>%
  select(-c(`1`)) %>%
  # filter(!all(is.na(.))) %>%
  #   Rows: 112
  # Columns: 159
  # filter(complete.cases(.)) %>%
  # Rows: 0
  unique() %>%
  glimpse()
  # write.csv(file = "fhier_logbooks_no_fl_county.csv", row.names = F)
  
```


## Spp. is 0
```{r spp. is 0}
## spp. is 0 ----
logbooks_content_transmission_date_ok %>%
  filter(!!sym(itis_field_name) == "0") %>%
  glimpse()
# Rows: 89

# grep("common", names(logbooks_content), value = T)
# common_name

logbooks_content_transmission_date_ok %>%
  filter(!!sym(itis_field_name) == "0") %>%
  select(common_name) %>% unique()
# NA

logbooks_content %>%
  filter(!!sym(itis_field_name) == "0") %>%
  select(trip_start_date) %>% unique()
# 70

logbooks_content_transmission_date_ok %>%
  filter(!!sym(itis_field_name) == "0") %>%
  glimpse()
# A tibble: 89 × 151
# write.csv(file = "logbooks_content_sp0.csv", row.names = F)

logbooks_content %>%
  filter(!!sym(itis_field_name) == "0") %>%
  # head()
  select(vessel_official_nbr) %>% unique()
```

## Questions 2. Check the vendor
(2) check the vendor. If it’s VMS, there’s not a lot we can do to ask the vendor to resolve but we can of course ask the auditing team to call the user for corrections. If it’s eTrips, we need to see if the vessel has our permits. Since a user can select any vessel in eTrips, it means we sometimes were getting reports from vessels that did not have our permit and so we’re no getting our questions. These we just need to filter out of the data. As of about 4 months ago, Yanet should be filtering all data to exclude vessels that did not have our permit(s).

```{r Check the vendor}
logbooks_content_transmission_date_ok_waves_fl_county %>%
  select(starts_with("notif"), user_app) %>%
  unique() %>%
  # Rows: 47,242
  # Columns: 33
  #   filter(complete.cases(.)) %>%
  # 0
  glimpse()

# user_app, system
grep("sta", names(not_specified_region), value = T)

grep("accsp", names(not_specified_region), value = T)

not_specified_region %>%
  filter(state_name == "FLORIDA") %>%
  select(starts_with("notif"),
         user_app,
         accsp_permit_license_nbr) %>%
  unique() %>%
  head()
```